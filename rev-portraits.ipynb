{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RnZ-l6lWaD59"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image as PImage, ImageDraw as PImageDraw\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G91m3OdpZpfS"
   },
   "outputs": [],
   "source": [
    "portrait_df = pd.read_csv(\"https://raw.githubusercontent.com/nmolnar-parsons/major-studio-1/refs/heads/main/Project_2/Data/cleaned.csv\")\n",
    "portrait_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwnUa6fvaI0J"
   },
   "outputs": [],
   "source": [
    "yolo_model_path = hf_hub_download(repo_id=\"AdamCodd/YOLOv11n-face-detection\", filename=\"model.pt\")\n",
    "face_detector = YOLO(yolo_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37xcSckNaMTB"
   },
   "outputs": [],
   "source": [
    "# create empty faces column\n",
    "portrait_df[\"faces\"] = \"\"\n",
    "\n",
    "# iterate through csv dataset\n",
    "for idx,row in list(portrait_df.iterrows())[:10]:\n",
    "  # parse mediaURLs field into a python list\n",
    "  mediaURLs = json.loads(row[\"mediaURLs\"].replace(\"'\", '\"'))\n",
    "\n",
    "  # skip if no urls\n",
    "  if len(mediaURLs) < 1:\n",
    "    continue\n",
    "\n",
    "  # dowload image\n",
    "  r = requests.get(mediaURLs[0])\n",
    "  oimg = PImage.open(BytesIO(r.content))\n",
    "\n",
    "  # resize to height of 256\n",
    "  iw,ih = oimg.size\n",
    "  nh = 256\n",
    "  nw = int(iw / ih * nh)\n",
    "  img = oimg.resize((nw, nh))\n",
    "\n",
    "  # detect faces\n",
    "  output = face_detector.predict(img, verbose=False)\n",
    "\n",
    "  # if no faces, skip\n",
    "  if len(output) < 1 or len(output[0]) < 1:\n",
    "    continue\n",
    "\n",
    "  # list of face boxes\n",
    "  faces_xyxy = output[0].boxes.xyxy.numpy()\n",
    "\n",
    "  # draw rect around faces (mostly for testing/debugging)\n",
    "  draw = PImageDraw.Draw(img)\n",
    "\n",
    "  for x0,y0,x1,y1 in faces_xyxy:\n",
    "    draw.rectangle(((x0,y0), (x1,y1)), outline=(200,0,0), width=2)\n",
    "  display(img)\n",
    "\n",
    "  # face boxes are scaled to our smaller sized image\n",
    "  #   this unscales them back to the coordinates in the original image\n",
    "  unscaled_faces_xyxy = []\n",
    "  for x0,y0,x1,y1 in faces_xyxy:\n",
    "    unscaled_faces_xyxy.append([\n",
    "      int(x0 * iw / nw),\n",
    "      int(y0 * ih / nh),\n",
    "      int(x1 * iw / nw),\n",
    "      int(y1 * ih / nh),\n",
    "    ])\n",
    "\n",
    "  # here the unscaled_faces_xyxy can be saved back to the dataset\n",
    "  portrait_df.at[idx, \"faces\"] = unscaled_faces_xyxy\n",
    "\n",
    "  # or we can use it to crop faces from images\n",
    "  for x0,y0,x1,y1 in unscaled_faces_xyxy:\n",
    "    face_img = oimg.crop((x0,y0,x1,y1))\n",
    "\n",
    "    # display the face\n",
    "    display(face_img)\n",
    "    # or save it\n",
    "    # face_img.save(\"some_file_name.jpg\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNT2md/1Tab5o3pSpCfSWp8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
